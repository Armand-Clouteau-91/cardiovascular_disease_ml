{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# 1. Feature Engineering (Data Prep)\n",
    "This notebook transforms the raw `cardio_train.csv` into a cleaned, feature-rich dataset ready for training.\\n**Output**: `../data/processed/final_dataset.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T21:28:33.538072Z",
     "iopub.status.busy": "2025-12-30T21:28:33.537569Z",
     "iopub.status.idle": "2025-12-30T21:28:34.458749Z",
     "shell.execute_reply": "2025-12-30T21:28:34.458497Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add source folder to path to import cleaning script\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import src.data.make_dataset as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_clean",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T21:28:34.460213Z",
     "iopub.status.busy": "2025-12-30T21:28:34.460103Z",
     "iopub.status.idle": "2025-12-30T21:28:34.495274Z",
     "shell.execute_reply": "2025-12-30T21:28:34.495035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data Shape: (69837, 12)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load and Clean Raw Data (Fix semicolons, remove impossible values)\n",
    "raw_path = \"../cardio_train.csv\" # Assume run from notebooks/\n",
    "if not os.path.exists(raw_path): # Handle path if running from root\n",
    "    raw_path = \"cardio_train.csv\"\n",
    "    \n",
    "df = md.data_cleaning(raw_path)\n",
    "print(f\"Raw Data Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feat_eng",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T21:28:34.496469Z",
     "iopub.status.busy": "2025-12-30T21:28:34.496398Z",
     "iopub.status.idle": "2025-12-30T21:28:34.665251Z",
     "shell.execute_reply": "2025-12-30T21:28:34.665017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Data Shape: (69837, 14)\n"
     ]
    }
   ],
   "source": [
    "# 2. Feature Engineering: The \"Standard\" Set (Champion)\n",
    "# Combines BMI, MAP, Categories, and Lifestyle Risk.\n",
    "\n",
    "def apply_standard_features(base_df):\n",
    "    df = base_df.copy()\n",
    "    \n",
    "    # --- Base Calculations ---\n",
    "    df[\"BMI\"] = df[\"weight\"] / ((df[\"height\"] / 100) ** 2)\n",
    "    df[\"map\"] = (df[\"ap_hi\"] + 2 * df[\"ap_lo\"]) / 3\n",
    "    \n",
    "    # --- Categorical Binning ---\n",
    "    def get_bmi_cat(bmi):\n",
    "        if bmi < 18.5: return 0\n",
    "        elif bmi < 25: return 1\n",
    "        elif bmi < 30: return 2\n",
    "        elif bmi < 35: return 3\n",
    "        elif bmi < 40: return 4\n",
    "        else: return 5\n",
    "    df[\"bmi_cat\"] = df[\"BMI\"].apply(get_bmi_cat)\n",
    "    \n",
    "    def get_bp_cat(row):\n",
    "        sys = row[\"ap_hi\"]\n",
    "        dia = row[\"ap_lo\"]\n",
    "        if sys > 180 or dia > 120: return 4\n",
    "        elif sys >= 140 or dia >= 90: return 3\n",
    "        elif sys >= 130 or dia >= 80: return 2\n",
    "        elif sys >= 120 and dia < 80: return 1\n",
    "        else: return 0\n",
    "    df[\"bp_cat\"] = df.apply(get_bp_cat, axis=1)\n",
    "    \n",
    "    df[\"lifestyle_risk\"] = df[\"smoke\"] + df[\"alco\"]\n",
    "    \n",
    "    # --- Risk Scores ---\n",
    "    risk_bmi = (df[\"BMI\"] >= 30).astype(int)\n",
    "    risk_bp = ((df[\"ap_hi\"] >= 130) | (df[\"ap_lo\"] >= 85)).astype(int)\n",
    "    risk_gluc = (df[\"gluc\"] > 1).astype(int)\n",
    "    risk_chol = (df[\"cholesterol\"] > 1).astype(int)\n",
    "    df[\"metabolic_score\"] = risk_bmi + risk_bp + risk_gluc + risk_chol\n",
    "    \n",
    "    # Drop Raw Columns used for calculation\n",
    "    return df.drop([\"weight\", \"height\", \"ap_hi\", \"ap_lo\"], axis=1)\n",
    "\n",
    "df_final = apply_standard_features(df)\n",
    "df_final = df_final.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "print(f\"Processed Data Shape: {df_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "save",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T21:28:34.666655Z",
     "iopub.status.busy": "2025-12-30T21:28:34.666564Z",
     "iopub.status.idle": "2025-12-30T21:28:34.788702Z",
     "shell.execute_reply": "2025-12-30T21:28:34.788464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to: ../data/processed/final_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# 3. Save to Disk\n",
    "output_dir = \"../data/processed\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "output_path = os.path.join(output_dir, \"final_dataset.csv\")\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(f\"Dataset saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
